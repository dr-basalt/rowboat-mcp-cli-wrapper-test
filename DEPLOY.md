# Guide de d√©ploiement - Rowboat HTTP Wrapper

## üì¶ R√©sum√© du projet

Ce projet expose **rowboatx** (un agent AI conversationnel) via une API HTTP REST pour permettre √† **Flowise** et autres outils d'agentflow de communiquer avec Rowboat via une interface web.

### Architecture

```
Flowise/Client HTTP ‚Üí API REST (Express) ‚Üí rowboatx (AI Agent) ‚Üí OpenAI GPT-4
```

## ‚úÖ Tests effectu√©s

- ‚úÖ Build Docker r√©ussi
- ‚úÖ Conteneur d√©marre correctement
- ‚úÖ Endpoint `/health` fonctionne
- ‚úÖ Endpoint `/chat` retourne des r√©ponses de Rowboat
- ‚úÖ Configuration OpenAI fonctionnelle
- ‚úÖ Timeout et gestion d'erreurs OK

### Exemples de requ√™tes test√©es

```bash
# Health check
curl http://localhost:3000/health
‚Üí {"status":"ok","service":"rowboat-http-wrapper","version":"1.0.0"}

# Chat simple
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"What can you do?"}'
‚Üí {"response":"Good day! How can I assist you with your workflows today?","timestamp":"..."}

# Chat complexe
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Can you help me create a workflow?"}'
‚Üí {"response":"Sure, I'm here to assist you with managing your workflows...","timestamp":"..."}
```

## üöÄ D√©ploiement sur Coolify

### √âtape 1 : Pr√©parer le repository GitHub

1. Cr√©er un nouveau repository GitHub (ou utiliser l'existant)
2. Pousser tous les fichiers de ce dossier :
   - `Dockerfile`
   - `package.json`
   - `server.js`
   - `entrypoint.sh`
   - `README.md`
   - `.gitignore`
   - `.env.example`

```bash
cd /root/rowboat-deployment
git init
git add .
git commit -m "Initial commit - Rowboat HTTP Wrapper"
git remote add origin https://github.com/VOTRE-USERNAME/VOTRE-REPO.git
git push -u origin main
```

### √âtape 2 : Configurer Coolify

1. Se connecter √† votre instance Coolify
2. Cr√©er une nouvelle application
3. S√©lectionner **"Docker"** comme type de build
4. Configurer :
   - **Repository** : URL de votre repository GitHub
   - **Branch** : `main`
   - **Build Pack** : Dockerfile
   - **Dockerfile Path** : `./Dockerfile` (racine du repo)

### √âtape 3 : Variables d'environnement

Dans Coolify, ajouter ces variables d'environnement :

| Variable | Valeur | Obligatoire |
|----------|--------|-------------|
| `OPENAI_API_KEY` | Votre cl√© API OpenAI (sk-proj-...) | ‚úÖ OUI |
| `PORT` | 3000 | ‚ùå Non (d√©faut: 3000) |
| `OPENAI_MODEL` | gpt-4 | ‚ùå Non (d√©faut: gpt-4) |
| `OPENAI_BASE_URL` | https://api.openai.com/v1 | ‚ùå Non |

**Important** : La cl√© `OPENAI_API_KEY` DOIT √™tre configur√©e pour que Rowboat fonctionne.

### √âtape 4 : Configuration du domaine

1. Dans Coolify, configurer le domaine/sous-domaine
2. Activer HTTPS (Let's Encrypt)
3. Port expos√© : **3000**

### √âtape 5 : D√©ployer

1. Cliquer sur **"Deploy"**
2. Attendre la fin du build (2-3 minutes)
3. V√©rifier les logs

### √âtape 6 : V√©rification

```bash
# Remplacer par votre domaine
DOMAIN="https://k84s4ogocgk8cow84wkcwcgo.jarvis.hosting.infra.ori3com.cloud"

# Test health
curl $DOMAIN/health

# Test chat
curl -X POST $DOMAIN/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello!"}'
```

## üîå Int√©gration avec Flowise

### M√©thode 1 : HTTP Request Node

1. Dans votre flow Flowise, ajouter un node **"HTTP Request"**
2. Configuration :
   - **Method** : POST
   - **URL** : `https://votre-domaine.com/chat`
   - **Headers** :
     ```json
     {
       "Content-Type": "application/json"
     }
     ```
   - **Body** :
     ```json
     {
       "message": "{{input}}"
     }
     ```

3. Ajouter un **"JSON Parser"** pour extraire le champ `response`
4. Connecter √† votre agent flow

### M√©thode 2 : Custom JavaScript Tool

```javascript
async function askRowboat(question) {
  const response = await fetch('https://votre-domaine.com/chat', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      message: question
    })
  });

  const data = await response.json();
  return data.response;
}

// Utilisation
const answer = await askRowboat("Create a workflow for data processing");
```

## üéØ Diff√©rence avec le d√©ploiement SuperGateway pr√©c√©dent

### Avant (avec SuperGateway)

```
Flowise ‚Üí SuperGateway (SSE/MCP protocol) ‚Üí rowboatx
                ‚ùå Incompatible : rowboatx n'est pas un serveur MCP
```

**Probl√®me** : rowboatx est un chatbot conversationnel, pas un serveur MCP JSON-RPC. SuperGateway attend des r√©ponses MCP conformes au protocole.

### Maintenant (HTTP simple)

```
Flowise ‚Üí API REST Express ‚Üí rowboatx (via stdin/stdout)
                ‚úÖ Compatible : communication en texte
```

**Solution** : Un wrapper HTTP simple qui :
- Accepte des messages en JSON via POST
- Lance rowboatx pour chaque requ√™te
- Capture la r√©ponse en texte
- Retourne un JSON propre

## üìä Performance

- **Temps de r√©ponse** : 3-5 secondes (d√©pend d'OpenAI)
- **Concurrence** : Une instance rowboat par requ√™te (stateless)
- **Timeout** : 60 secondes par requ√™te
- **Scalabilit√©** : Horizontal (ajouter plus d'instances si n√©cessaire)

## üêõ Troubleshooting

### Le serveur ne d√©marre pas

**V√©rifier les logs Coolify :**
```bash
# Sur le VPS
docker logs <container-name>
```

**Probl√®mes courants :**
- `OPENAI_API_KEY` non configur√©e ‚Üí Ajouter dans Coolify
- Port d√©j√† utilis√© ‚Üí Changer le PORT dans les variables

### Rowboat ne r√©pond pas / Timeout

**Causes possibles :**
1. Cl√© API OpenAI invalide/expir√©e
2. Quota OpenAI d√©pass√©
3. Probl√®me r√©seau vers OpenAI

**Solution :**
- V√©rifier la cl√© API
- V√©rifier les quotas sur platform.openai.com
- Regarder les logs du conteneur

### R√©ponses vides ou erreurs d'extraction

Le code extrait automatiquement la r√©ponse entre les marqueurs `Response` et `Finish` dans le output de rowboat.

Si √ßa √©choue, v√©rifier les logs :
```bash
docker logs <container> | grep "Failed to extract"
```

## üîí S√©curit√©

### Recommandations

1. **API Key** : Ne jamais commiter la cl√© OpenAI dans Git
2. **HTTPS** : Toujours utiliser HTTPS (activ√© par Coolify)
3. **Rate Limiting** : Ajouter un rate limiter si usage public
4. **CORS** : Actuellement ouvert (`*`), restreindre si n√©cessaire

### Ajouter un rate limiter (optionnel)

```bash
# Dans package.json
"dependencies": {
  "express": "^4.18.2",
  "cors": "^2.8.5",
  "express-rate-limit": "^6.10.0"
}
```

```javascript
// Dans server.js
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // max 100 requ√™tes par IP
});

app.use('/chat', limiter);
```

## üìù Logs et monitoring

### Voir les logs en temps r√©el

```bash
docker logs -f <container-name>
```

### Logs importants √† surveiller

```
‚úÖ OPENAI_API_KEY is set          ‚Üí Configuration OK
üöÄ Rowboat HTTP Server             ‚Üí Serveur d√©marr√©
[Chat] Received message: ...       ‚Üí Requ√™te re√ßue
[Rowboat] Response extracted ...   ‚Üí R√©ponse captur√©e
[Rowboat] Timeout ...              ‚Üí ‚ö†Ô∏è Probl√®me de performance
```

## üîÑ Mise √† jour

Pour mettre √† jour le code :

1. Modifier les fichiers localement
2. Push vers GitHub
3. Dans Coolify, cliquer sur "Redeploy"
4. Coolify rebuild et red√©ploie automatiquement

## üìû Support

En cas de probl√®me :

1. V√©rifier les logs Docker
2. Tester les endpoints avec curl
3. V√©rifier la configuration Coolify
4. V√©rifier la cl√© OpenAI

## ‚ú® Am√©liorations futures possibles

- [ ] Ajouter une gestion de sessions persistantes
- [ ] Impl√©menter un syst√®me de cache pour les r√©ponses fr√©quentes
- [ ] Ajouter des m√©triques (Prometheus/Grafana)
- [ ] Supporter d'autres mod√®les AI
- [ ] Ajouter une authentification API
- [ ] WebSocket pour streaming des r√©ponses
